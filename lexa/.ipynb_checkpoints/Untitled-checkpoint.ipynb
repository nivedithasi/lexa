{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(episodes, config):\n",
    "  example = episodes[next(iter(episodes.keys()))]\n",
    "  types = {k: v.dtype for k, v in example.items()}\n",
    "  shapes = {k: (None,) + v.shape[1:] for k, v in example.items()}\n",
    "  generator = lambda: tools.sample_episodes(\n",
    "      episodes, config.batch_length, config.oversample_ends)\n",
    "  dataset = tf.data.Dataset.from_generator(generator, types, shapes)\n",
    "  dataset = dataset.batch(config.batch_size, drop_remainder=True)\n",
    "  dataset = dataset.prefetch(10)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFolder(tf.data.Dataset):\n",
    "\n",
    "  # tf.data.Dataset.from_generator(generator, types, shapes)\n",
    "\n",
    "  def __init__(self, args, root, json_file_input, json_file_labels, clip_size,\n",
    "                 nclips, step_size, is_val, num_tasks=174, transform_pre=None, transform_post=None,\n",
    "                 augmentation_mappings_json=None, augmentation_types_todo=None,\n",
    "                 is_test=False, robot_demo_transform=None):\n",
    "    self.num_tasks = num_tasks\n",
    "    self.is_val = is_val\n",
    "\n",
    "    # Gets data from json files?\n",
    "    self.dataset_object = WebmDataset(args, json_file_input, json_file_labels,\n",
    "                                      root, num_tasks=self.num_tasks, is_test=is_test, is_val=is_val)\n",
    "        \n",
    "    self.json_data = self.dataset_object.json_data # json data from the webm dataset\n",
    "    self.classes = self.dataset_object.classes\n",
    "    self.classes_dict = self.dataset_object.classes_dict\n",
    "    self.root = root\n",
    "    self.transform_pre = transform_pre\n",
    "    self.transform_post = transform_post\n",
    "    self.im_size = args.im_size\n",
    "    self.batch_size = args.batch_size\n",
    "\n",
    "    #self.augmentor = Augmentor(augmentation_mappings_json, augmentation_types_todo)\n",
    "\n",
    "    self.traj_length = clip_size\n",
    "    self.nclips = nclips\n",
    "    self.step_size = step_size\n",
    "    self.similarity = args.similarity\n",
    "    self.add_demos = args.add_demos \n",
    "    if self.add_demos:\n",
    "            self.robot_demo_transform = robot_demo_transform\n",
    "            self.demo_batch_val = args.demo_batch_val\n",
    "        \n",
    "    # add keys to list called classes if they are not ints\n",
    "    classes = []\n",
    "    for key in self.classes_dict.keys():\n",
    "        if not isinstance(key, int):\n",
    "            classes.append(key)\n",
    "\n",
    "    self.classes = classes\n",
    "    num_occur = defaultdict(int)\n",
    "    # make a dict with key = class, value = num_occurances\n",
    "    for c in self.classes:\n",
    "        for video in self.json_data:\n",
    "            if video.label == c:\n",
    "                num_occur[c] += 1\n",
    "\n",
    "    # dump the occrance dict to a file\n",
    "    if not self.is_val:\n",
    "        with open(args.log_dir + '/human_data_tasks.txt', 'w') as f:\n",
    "            json.dump(num_occur, f, indent=2)\n",
    "    else:\n",
    "        with open(args.log_dir + '/val_human_data_tasks.txt', 'w') as f:\n",
    "            json.dump(num_occur, f, indent=2)\n",
    "                \n",
    "    # Every sample in batch: anchor (randomly selected class A), positive (randomly selected class A), \n",
    "    # and negative (randomly selected class not A)\n",
    "    # Make dictionary for similarity triplets\n",
    "    \n",
    "    self.json_dict = defaultdict(list)\n",
    "    for data in self.json_data:\n",
    "        self.json_dict[data.label].append(data)\n",
    "\n",
    "    # Make separate robot dictionary:\n",
    "    self.robot_json_dict = defaultdict(list)\n",
    "    self.total_robot = [] # all robot demos\n",
    "    \n",
    "    for data in self.json_data:\n",
    "        if data.id == 300000: # robot video\n",
    "            self.robot_json_dict[data.label].append(data)\n",
    "            self.total_robot.append(data)\n",
    "            \n",
    "    print(\"Number of human videos: \", len(self.json_data), len(self.classes), \"Total:\", self.__len__())\n",
    "        \n",
    "    # Tasks used\n",
    "    self.tasks = args.human_tasks\n",
    "    if self.add_demos:\n",
    "        self.robot_tasks = args.robot_tasks\n",
    "    assert(sum(num_occur.values()) == len(self.json_data))        \n",
    "\n",
    "  def process_video(self, item):\n",
    "    # Open video file\n",
    "    try: \n",
    "        reader = av.open(item.path)\n",
    "    except:\n",
    "        print(\"Issue with opening the video, path:\", item.path)\n",
    "        assert(False)\n",
    "\n",
    "    try:\n",
    "        imgs = []\n",
    "        imgs = [f.to_rgb().to_ndarray() for f in reader.decode(video=0)]\n",
    "    except (RuntimeError, ZeroDivisionError) as exception:\n",
    "        print('{}: WEBM reader cannot open {}. Empty '\n",
    "                  'list returned.'.format(type(exception).__name__, item.path))\n",
    "    \n",
    "    orig_imgs = np.array(imgs).copy() \n",
    "        \n",
    "    target_idx = self.classes_dict[item.label] \n",
    "    # not sure what this does\n",
    "    if not self.num_tasks == 174:\n",
    "        target_idx = self.tasks.index(target_idx)\n",
    "            \n",
    "    # If robot demonstration\n",
    "    # get trajectory length clips from video\n",
    "    if self.add_demos and item.id == 300000: \n",
    "            imgs = self.robot_demo_transform(imgs)\n",
    "            frame = random.randint(0, max(len(imgs) - self.traj_length, 0))\n",
    "            length = min(self.traj_length, len(imgs))\n",
    "            imgs = imgs[frame: length + frame]\n",
    "            imgs_copy = tf.stack(imgs)\n",
    "            imgs_copy = imgs_copy.permute(1, 0, 2, 3)\n",
    "            return imgs_copy\n",
    "        \n",
    "    imgs = self.transform_pre(imgs)\n",
    "    imgs, label = self.augmentor(imgs, item.label)\n",
    "    imgs = self.transform_post(imgs)\n",
    "        \n",
    "    num_frames = len(imgs)        \n",
    "    if self.nclips > -1:\n",
    "        num_frames_necessary = self.traj_length * self.nclips * self.step_size\n",
    "    else:\n",
    "        num_frames_necessary = num_frames\n",
    "    offset = 0\n",
    "    if num_frames_necessary < num_frames:\n",
    "        # If there are more frames, then sample starting offset.\n",
    "        diff = (num_frames - num_frames_necessary)\n",
    "        # temporal augmentation\n",
    "        offset = np.random.randint(0, diff)\n",
    "\n",
    "    imgs = imgs[offset: num_frames_necessary + offset: self.step_size]\n",
    "    if len(imgs) < (self.traj_length * self.nclips):\n",
    "        imgs.extend([imgs[-1]] *\n",
    "                        ((self.traj_length * self.nclips) - len(imgs)))\n",
    "\n",
    "    # format data to torch\n",
    "    data = tf.stack(imgs)\n",
    "    data = data.permute(1, 0, 2, 3)\n",
    "    return data\n",
    "    \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        [!] FPS jittering doesn't work with AV dataloader as of now\n",
    "        \"\"\"\n",
    "            \n",
    "        if self.similarity:\n",
    "            # Need triplet for each sample\n",
    "            if self.add_demos and np.random.uniform(0.0, 1.0) < self.demo_batch_val:\n",
    "                item = random.choice(self.total_robot)\n",
    "            else:\n",
    "                item = random.choice(self.json_data) \n",
    "            \n",
    "            # Get random anchor\n",
    "            # If adding demos, get 1/2 robot anchors for a more balanced batch\n",
    "            if self.add_demos and (self.classes_dict[item.label] in self.robot_tasks) and (np.random.uniform(0.0, 1.0) < self.demo_batch_val): \n",
    "                anchor = random.choice(self.robot_json_dict[item.label])\n",
    "            else:\n",
    "                anchor = random.choice(self.json_dict[item.label])\n",
    "            \n",
    "            # Get negative \n",
    "            neg = random.choice(self.json_data)\n",
    "            if self.add_demos and np.random.uniform(0.0, 1.0) < self.demo_batch_val: \n",
    "                neg = random.choice(self.total_robot)\n",
    "            while neg.label == item.label:\n",
    "                neg = random.choice(self.json_data)\n",
    "                \n",
    "            pos_data = self.process_video(item)  \n",
    "            anchor_data  = self.process_video(anchor)\n",
    "            neg_data = self.process_video(neg)\n",
    "\n",
    "            # return teo clips per task\n",
    "            return (pos_data, anchor_data, neg_data)\n",
    "            \n",
    "    def __len__(self):\n",
    "        self.total_files = len(self.json_data)\n",
    "        if self.similarity and not self.is_val and self.num_tasks <= 12:\n",
    "            self.total_files = self.batch_size * 200 \n",
    "        return self.total_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class VideoFolder with abstract methods _inputs, element_spec",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7c4aee388c26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_data = VideoFolder(root='/iris/u/asc8/workspace/humans/Humans/20bn-something-something-v2-all-videos/',\n\u001b[0m\u001b[1;32m      2\u001b[0m                            \u001b[0mjson_file_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/iris/u/surajn/workspace/language_offline_rl/sthsth/something-something-v2-train.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                            \u001b[0mjson_file_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/iris/u/surajn/workspace/language_offline_rl/sthsth/something-something-v2-labels.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mclip_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m72\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            \u001b[0mnclips\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class VideoFolder with abstract methods _inputs, element_spec"
     ]
    }
   ],
   "source": [
    "train_data = VideoFolder(root='/iris/u/asc8/workspace/humans/Humans/20bn-something-something-v2-all-videos/',\n",
    "                           json_file_input='/iris/u/surajn/workspace/language_offline_rl/sthsth/something-something-v2-train.json',\n",
    "                           json_file_labels='/iris/u/surajn/workspace/language_offline_rl/sthsth/something-something-v2-labels.json',\n",
    "                           clip_size=72,\n",
    "                           nclips=1,\n",
    "                           step_size=1,\n",
    "                           is_val=False,\n",
    "                           get_item_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = VideoFolder(root='/iris/u/asc8/workspace/humans/Humans/20bn-something-something-v2-all-videos/',\n",
    "                           json_file_input='/iris/u/surajn/workspace/language_offline_rl/sthsth/something-something-v2-train.json',\n",
    "                           json_file_labels='/iris/u/surajn/workspace/language_offline_rl/sthsth/something-something-v2-labels.json',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "f = open('/iris/u/surajn/workspace/language_offline_rl/sthsth/something-something-v2-train.json')\n",
    "data = json.load(f)\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetBase(object):\n",
    "    \"\"\"\n",
    "    To read json data and construct a list containing video sample `ids`,\n",
    "    `label` and `path`\n",
    "    \"\"\"\n",
    "    def __init__(self, root, json_path_input, json_path_labels, is_test=False, is_val=False):\n",
    "        self.num_tasks = num_tasks\n",
    "        self.json_path_input = json_path_input\n",
    "        self.json_path_labels = json_path_labels\n",
    "        self.data_root = data_root\n",
    "        self.extension = extension\n",
    "        self.is_test = is_test\n",
    "        self.is_val = is_val\n",
    "        self.just_robot = args.just_robot\n",
    "        self.sim_dir = args.sim_dir\n",
    "        \n",
    "        self.num_occur = defaultdict(int)\n",
    "        \n",
    "        self.tasks = args.human_tasks\n",
    "        self.add_demos = args.add_demos\n",
    "        if self.add_demos:\n",
    "            self.robot_tasks = args.robot_tasks\n",
    "\n",
    "        # preparing data and class dictionary\n",
    "        self.classes = self.read_json_labels()\n",
    "        self.classes_dict = self.get_two_way_dict(self.classes)\n",
    "        self.json_data = self.read_json_input()\n",
    "        print(\"Number of human videos:\", self.num_occur.values())\n",
    "        \n",
    "        \n",
    "    def read_json_input(self):\n",
    "        json_data = []\n",
    "        if not self.is_test:\n",
    "            if not self.just_robot: #not self.triplet or not self.add_demos: #self.is_val or\n",
    "                with open(self.json_path_input, 'rb') as jsonfile:\n",
    "                    json_reader = json.load(jsonfile)\n",
    "                    for elem in json_reader:\n",
    "                        label = self.clean_template(elem['template'])\n",
    "                        if label not in self.classes_dict.keys(): # or label == 'Pushing something so that it slightly moves':\n",
    "                            continue\n",
    "                        if label not in self.classes:\n",
    "                            raise ValueError(\"Label mismatch! Please correct\")\n",
    "                        \n",
    "                        label_num = self.classes_dict[label]\n",
    "                        item = ListData(elem['id'],\n",
    "                                        label,\n",
    "                                        os.path.join(self.data_root,\n",
    "                                                     elem['id'] + self.extension)\n",
    "                                        )\n",
    "                        json_data.append(item)\n",
    "                        self.num_occur[label] += 1\n",
    "            \n",
    "            if self.add_demos: \n",
    "                # Add robot demonstrations or extra robot class to json_data, just use id 300000\n",
    "                robot_tasks = self.robot_tasks\n",
    "                root_in_dir = self.sim_dir \n",
    "                for label_num in robot_tasks: \n",
    "                    # add task demos for task label_num\n",
    "                    in_dirs = [f'{root_in_dir}/env1/task{label_num}_webm', f'{root_in_dir}/env1_rearranged/task{label_num}_webm']\n",
    "                        \n",
    "                    for in_dir in in_dirs:\n",
    "                        label = self.classes_dict[label_num]\n",
    "\n",
    "                        num_demos = self.add_demos\n",
    "                        self.num_occur[label] += num_demos\n",
    "                        if not self.is_val: \n",
    "                            for j in range(num_demos):\n",
    "                                item = ListData(300000,\n",
    "                                            label,\n",
    "                                            os.path.join(in_dir, str(j) + self.extension)\n",
    "                                            )\n",
    "                                json_data.append(item)\n",
    "                        else:\n",
    "                            for j in range(num_demos, int(1.4*num_demos)):\n",
    "                                item = ListData(300000,\n",
    "                                            label,\n",
    "                                            os.path.join(in_dir, str(j) + self.extension)\n",
    "                                            )\n",
    "                                json_data.append(item)\n",
    "                        \n",
    "\n",
    "        else:\n",
    "            with open(self.json_path_input, 'rb') as jsonfile:\n",
    "                json_reader = json.load(jsonfile)\n",
    "                for elem in json_reader:\n",
    "                    # add a dummy label for all test samples\n",
    "                    item = ListData(elem['id'],\n",
    "                                    \"Holding something\",\n",
    "                                    os.path.join(self.data_root,\n",
    "                                                 elem['id'] + self.extension)\n",
    "                                    )\n",
    "                    json_data.append(item)\n",
    "        return json_data\n",
    "\n",
    "    def read_json_labels(self):\n",
    "        classes = []\n",
    "        with open(self.json_path_labels, 'rb') as jsonfile:\n",
    "            json_reader = json.load(jsonfile)\n",
    "            for elem in json_reader:\n",
    "                classes.append(elem)\n",
    "        return sorted(classes)\n",
    "\n",
    "    def get_two_way_dict(self, classes):\n",
    "        classes_dict = {} \n",
    "        tasks = self.tasks\n",
    "        for i, item in enumerate(classes):\n",
    "            if i not in tasks:\n",
    "                continue\n",
    "            classes_dict[item] = i\n",
    "            classes_dict[i] = item\n",
    "        print(\"Length of keys\", len(classes_dict.keys()), classes_dict.keys())\n",
    "        return classes_dict\n",
    "\n",
    "    def clean_template(self, template):\n",
    "        \"\"\" Replaces instances of `[something]` --> `something`\"\"\"\n",
    "        template = template.replace(\"[\", \"\")\n",
    "        template = template.replace(\"]\", \"\")\n",
    "        return template\n",
    "\n",
    "\n",
    "class WebmDataset(DatasetBase):\n",
    "    def __init__(self, args, json_path_input, json_path_labels, data_root, num_tasks, \n",
    "                 is_test=False, is_val=False):\n",
    "        EXTENSION = \".webm\"\n",
    "        super().__init__(args, json_path_input, json_path_labels, data_root,\n",
    "                         EXTENSION, num_tasks, is_test, is_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.dataset_object = WebmDataset(args, json_file_input, json_file_labels,\n",
    "                                      root, num_tasks=self.num_tasks, is_test=is_test, is_val=is_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    args.im_size_x = int(args.im_size * 1.5)\n",
    "    args.json_data_train = args.root + \"something-something-v2-train.json\"\n",
    "    args.json_data_val = args.root + \"something-something-v2-validation.json\"\n",
    "    args.json_data_test = args.root + \"something-something-v2-test.json\"\n",
    "    args.json_file_labels = args.root + \"something-something-v2-labels.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = VideoFolder(root='/iris/u/asc8/workspace/humans/Humans/20bn-something-something-v2-all-videos/',\n",
    "                           json_file_input='/iris/u/surajn/workspace/language_offline_rl/sthsth/something-something-v2-train.json',\n",
    "                           json_file_labels='/iris/u/surajn/workspace/language_offline_rl/sthsth/something-something-v2-labels.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFolder(tf.data.Dataset):\n",
    "\n",
    "  # tf.data.Dataset.from_generator(generator, types, shapes)\n",
    "\n",
    "  def __init__(self, root, json_file_input, json_file_labels, clip_size=None,\n",
    "                 nclips=None, step_size=None, is_val=None, num_tasks=174, transform_pre=None, transform_post=None,\n",
    "                 augmentation_mappings_json=None, augmentation_types_todo=None,\n",
    "                 is_test=False, robot_demo_transform=None):\n",
    "    self.num_tasks = num_tasks\n",
    "    self.is_val = is_val\n",
    "\n",
    "    self.dataset_object = WebmDataset(args, json_file_input, json_file_labels,\n",
    "                                      root, num_tasks=self.num_tasks, is_test=is_test, is_val=is_val)\n",
    "        \n",
    "    self.json_data = self.dataset_object.json_data # json data from the webm dataset\n",
    "    self.classes = self.dataset_object.classes\n",
    "    self.classes_dict = self.dataset_object.classes_dict\n",
    "    self.root = root\n",
    "    self.transform_pre = transform_pre\n",
    "    self.transform_post = transform_post\n",
    "    self.im_size = args.im_size\n",
    "    self.batch_size = args.batch_size\n",
    "\n",
    "    #self.augmentor = Augmentor(augmentation_mappings_json, augmentation_types_todo)\n",
    "\n",
    "    self.traj_length = clip_size\n",
    "    self.nclips = nclips\n",
    "    self.step_size = step_size\n",
    "    self.similarity = args.similarity\n",
    "    self.add_demos = args.add_demos \n",
    "    if self.add_demos:\n",
    "            self.robot_demo_transform = robot_demo_transform\n",
    "            self.demo_batch_val = args.demo_batch_val\n",
    "        \n",
    "    # add keys to list called classes if they are not ints\n",
    "    classes = []\n",
    "    for key in self.classes_dict.keys():\n",
    "        if not isinstance(key, int):\n",
    "            classes.append(key)\n",
    "\n",
    "    self.classes = classes\n",
    "    num_occur = defaultdict(int)\n",
    "    # make a dict with key = class, value = num_occurances\n",
    "    for c in self.classes:\n",
    "        for video in self.json_data:\n",
    "            if video.label == c:\n",
    "                num_occur[c] += 1\n",
    "\n",
    "    # dump the occrance dict to a file\n",
    "    if not self.is_val:\n",
    "        with open(args.log_dir + '/human_data_tasks.txt', 'w') as f:\n",
    "            json.dump(num_occur, f, indent=2)\n",
    "    else:\n",
    "        with open(args.log_dir + '/val_human_data_tasks.txt', 'w') as f:\n",
    "            json.dump(num_occur, f, indent=2)\n",
    "                \n",
    "    # Every sample in batch: anchor (randomly selected class A), positive (randomly selected class A), \n",
    "    # and negative (randomly selected class not A)\n",
    "    # Make dictionary for similarity triplets\n",
    "    \n",
    "    self.json_dict = defaultdict(list)\n",
    "    for data in self.json_data:\n",
    "        self.json_dict[data.label].append(data)\n",
    "\n",
    "    # Make separate robot dictionary:\n",
    "    self.robot_json_dict = defaultdict(list)\n",
    "    self.total_robot = [] # all robot demos\n",
    "    \n",
    "    for data in self.json_data:\n",
    "        if data.id == 300000: # robot video\n",
    "            self.robot_json_dict[data.label].append(data)\n",
    "            self.total_robot.append(data)\n",
    "            \n",
    "    print(\"Number of human videos: \", len(self.json_data), len(self.classes), \"Total:\", self.__len__())\n",
    "        \n",
    "    # Tasks used\n",
    "    self.tasks = args.human_tasks\n",
    "    if self.add_demos:\n",
    "        self.robot_tasks = args.robot_tasks\n",
    "    assert(sum(num_occur.values()) == len(self.json_data))        \n",
    "\n",
    "  def process_video(self, item):\n",
    "    # Open video file\n",
    "    try: \n",
    "        reader = av.open(item.path)\n",
    "    except:\n",
    "        print(\"Issue with opening the video, path:\", item.path)\n",
    "        assert(False)\n",
    "\n",
    "    try:\n",
    "        imgs = []\n",
    "        imgs = [f.to_rgb().to_ndarray() for f in reader.decode(video=0)]\n",
    "    except (RuntimeError, ZeroDivisionError) as exception:\n",
    "        print('{}: WEBM reader cannot open {}. Empty '\n",
    "                  'list returned.'.format(type(exception).__name__, item.path))\n",
    "    \n",
    "    orig_imgs = np.array(imgs).copy() \n",
    "        \n",
    "    target_idx = self.classes_dict[item.label] \n",
    "    # not sure what this does\n",
    "    if not self.num_tasks == 174:\n",
    "        target_idx = self.tasks.index(target_idx)\n",
    "            \n",
    "    # If robot demonstration\n",
    "    # get trajectory length clips from video\n",
    "    if self.add_demos and item.id == 300000: \n",
    "            imgs = self.robot_demo_transform(imgs)\n",
    "            frame = random.randint(0, max(len(imgs) - self.traj_length, 0))\n",
    "            length = min(self.traj_length, len(imgs))\n",
    "            imgs = imgs[frame: length + frame]\n",
    "            imgs_copy = tf.stack(imgs)\n",
    "            imgs_copy = imgs_copy.permute(1, 0, 2, 3)\n",
    "            return imgs_copy\n",
    "        \n",
    "    imgs = self.transform_pre(imgs)\n",
    "    imgs, label = self.augmentor(imgs, item.label)\n",
    "    imgs = self.transform_post(imgs)\n",
    "        \n",
    "    num_frames = len(imgs)        \n",
    "    if self.nclips > -1:\n",
    "        num_frames_necessary = self.traj_length * self.nclips * self.step_size\n",
    "    else:\n",
    "        num_frames_necessary = num_frames\n",
    "    offset = 0\n",
    "    if num_frames_necessary < num_frames:\n",
    "        # If there are more frames, then sample starting offset.\n",
    "        diff = (num_frames - num_frames_necessary)\n",
    "        # temporal augmentation\n",
    "        offset = np.random.randint(0, diff)\n",
    "\n",
    "    imgs = imgs[offset: num_frames_necessary + offset: self.step_size]\n",
    "    if len(imgs) < (self.traj_length * self.nclips):\n",
    "        imgs.extend([imgs[-1]] *\n",
    "                        ((self.traj_length * self.nclips) - len(imgs)))\n",
    "\n",
    "    # format data to torch\n",
    "    data = tf.stack(imgs)\n",
    "    data = data.permute(1, 0, 2, 3)\n",
    "    return data\n",
    "    \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        [!] FPS jittering doesn't work with AV dataloader as of now\n",
    "        \"\"\"\n",
    "            \n",
    "        if self.similarity:\n",
    "            # Need triplet for each sample\n",
    "            if self.add_demos and np.random.uniform(0.0, 1.0) < self.demo_batch_val:\n",
    "                item = random.choice(self.total_robot)\n",
    "            else:\n",
    "                item = random.choice(self.json_data) \n",
    "            \n",
    "            # Get random anchor\n",
    "            # If adding demos, get 1/2 robot anchors for a more balanced batch\n",
    "            if self.add_demos and (self.classes_dict[item.label] in self.robot_tasks) and (np.random.uniform(0.0, 1.0) < self.demo_batch_val): \n",
    "                anchor = random.choice(self.robot_json_dict[item.label])\n",
    "            else:\n",
    "                anchor = random.choice(self.json_dict[item.label])\n",
    "            \n",
    "            # Get negative \n",
    "            neg = random.choice(self.json_data)\n",
    "            if self.add_demos and np.random.uniform(0.0, 1.0) < self.demo_batch_val: \n",
    "                neg = random.choice(self.total_robot)\n",
    "            while neg.label == item.label:\n",
    "                neg = random.choice(self.json_data)\n",
    "                \n",
    "            pos_data = self.process_video(item)  \n",
    "            anchor_data  = self.process_video(anchor)\n",
    "            neg_data = self.process_video(neg)\n",
    "\n",
    "            # return teo clips per task\n",
    "            return (pos_data, anchor_data, neg_data)\n",
    "            \n",
    "    def __len__(self):\n",
    "        self.total_files = len(self.json_data)\n",
    "        if self.similarity and not self.is_val and self.num_tasks <= 12:\n",
    "            self.total_files = self.batch_size * 200 \n",
    "        return self.total_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
