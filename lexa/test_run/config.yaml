!!python/object:argparse.Namespace
act: !!python/name:tensorflow.python.ops.gen_nn_ops.elu ''
action_repeat: 2
actor_disc: 5
actor_dist: trunc_normal
actor_entropy: '1e-4'
actor_grad_clip: 100
actor_init_std: 1.0
actor_layers: 4
actor_lr: 8e-05
actor_min_std: 0.1
actor_outscale: 0.0
actor_state_entropy: 0.0
actor_temp: 0.1
atari_grayscale: false
batch_length: 50
batch_size: 45
behavior_stop_grad: true
clip_rewards: identity
cnn_depth: 32
collect_dyn_sample: true
dataset_size: 1000000.0
dd_distance: steps_to_go
dd_inp: embed
dd_loss: regression
dd_neg_sampling_factor: 0
dd_norm_inp: false
dd_norm_reg_label: true
dd_num_positives: 256
dd_prob_balance: 1.0
dd_train_imag: true
dd_train_off_policy: false
debug: false
decoder_kernels: !!python/tuple
- 5
- 5
- 6
- 6
decoder_thin: true
disag_layers: 4
disag_log: true
disag_models: 10
disag_offset: 1
disag_target: stoch
disag_units: 400
discount: 0.99
discount_lambda: 0.95
discount_layers: 3
discount_scale: 1.0
dyn_cell: gru_layer_norm
dyn_deter: 200
dyn_discrete: 0
dyn_hidden: 200
dyn_input_layers: 1
dyn_mean_act: none
dyn_min_std: 0.1
dyn_output_layers: 1
dyn_shared: false
dyn_std_act: sigmoid2
dyn_stoch: 50
ee_control_mode: end_effector
encoder_cls: vanilla
encoder_kernels: !!python/tuple
- 4
- 4
- 4
- 4
envs: 1
eval_every: 25000.0
eval_noise: 0.0
eval_state_mean: false
evaldir: !!python/object/apply:pathlib.PosixPath
- test_run
- eval_eps
expl_amount: 0.0
expl_behavior: plan2explore
expl_every_ep: 2
expl_extr_scale: 0.0
expl_gifs: false
expl_intr_scale: 1.0
expl_until: -100
future_entropy: false
gc_input: embed
gc_reward: dynamical_distance
gcbc: false
gcbc_distance_weighting: false
gpu_growth: true
grad_clip: 100
grad_heads: !!python/tuple
- image
- reward
imag_gradient: dynamics
imag_gradient_mix: 1.0
imag_horizon: 15
imag_on_policy: true
imag_sample: true
kl_balance: '0.8'
kl_free: '1.0'
kl_scale: '1.0'
labelled_env_multiplexing: false
latent_constraint: ''
log_every: 5000.0
model_lr: 0.0003
offline_evaldir: ''
offline_traindir: ''
offpolicy_opt: false
offpolicy_use_embed: false
opt: adam
opt_eps: 1e-05
oversample_ends: false
precision: 16
pred_discount: false
pred_embed: true
pred_reward: false
pred_stoch_state: false
prefill: 2500
pretrain: 100
relabel_fraction: 0.5
relabel_mode: geometric
reset_env: true
reset_every: 0
reward_layers: 2
reward_scale: 2.0
rp_grad_clip: 100
rp_lr: 8e-05
seed: 0
size: !!python/tuple
- 64
- 64
skill_dim: 16
skill_pred_input: feat
skill_pred_noise: 0
slow_actor_target: true
slow_target_fraction: 1
slow_target_update: 100
slow_value_target: true
state_rep_for_policy: feat
steps: 50000000.0
sync_s3: false
task: kitchen
task_behavior: gcdreamer
test_log_per_goal: false
time_limit: 75
train_every: 5
train_off_policy_every: 5
train_steps: 1
traindir: !!python/object/apply:pathlib.PosixPath
- test_run
- train_eps
training: true
training_goals: batch
units: 400
value_decay: 0.0
value_grad_clip: 100
value_head: normal
value_layers: 3
value_lr: 8e-05
weight_decay: 0.0
